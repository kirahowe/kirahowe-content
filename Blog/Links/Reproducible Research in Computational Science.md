---
link: https://pmc.ncbi.nlm.nih.gov/articles/PMC3383002/?ref=data-school
via: https://www.coursera.org/lecture/reproducible-research/reproducible-research-concepts-and-ideas-part-2-abevs
tags:
  - papers
  - reproducibility
  - research
date: 2025-01-06
---
I came across this paper through another [Coursera course I'm exploring about reproducible research](https://www.coursera.org/learn/reproducible-research/) in preparation for a [talk I'm giving in March](https://bobkonf.de/2025/howe.html) and found it both enlightening and a little depressing. Enlightening because it offers an interesting perspective on some of the problems with the current state of data work that contribute to the [replication crisis](https://en.wikipedia.org/wiki/Replication_crisis). As a software engineer, it's wild to me that it was not just acceptable but totally normal and inoffensive to publish exclusively the results of a computation, without providing any data or code that could allow someone else to reproduce the results. This is improving since the time this paper was published, but it is still very standard to find no indication of how a given analysis was run or result was achieved in a given paper.

The author describes one system their team at the journal _Biostatistics_ implemented to tag papers with confirmed reproducible results which, at the time of this paper's publication, had been done successfully on **5 out of 125** papers. That was a little depressing to read. The author later points out that, like so many things in life, the standard we get is really just whatever the community is willing to expect and enforce.